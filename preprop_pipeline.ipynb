{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQwD6Yee78iDZW2SHEZ67N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avkaz/DeepLearningPetIdentification/blob/preprocess_pipeline/preprop_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "J5yEKEaHmNW3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image, ExifTags, ImageDraw\n",
        "import requests\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from itertools import islice\n",
        "\n",
        "# Metadata Fetching\n",
        "def get_data():\n",
        "    \"\"\"\n",
        "    Fetches and parses JSON data from the given URL.\n",
        "\n",
        "    Returns:\n",
        "        dict: The parsed JSON data as a Python dictionary.\n",
        "    \"\"\"\n",
        "    url = \"https://raw.githubusercontent.com/avkaz/DeepLearningPetIdentification/main/pets_db.json\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"An error occurred while fetching data: {e}\")\n",
        "        raise\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"An error occurred while parsing JSON: {e}\")\n",
        "        raise\n",
        "\n",
        "# Model Loading\n",
        "detector = None\n",
        "MODEL_URL = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of \"pets\", where metadata: \"images\" is empty."
      ],
      "metadata": {
        "id": "3D66ZMUl1GD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_detector_model():\n",
        "    global detector\n",
        "    if detector is None:\n",
        "        print(\"Uploading model...\")\n",
        "        detector = hub.load(MODEL_URL).signatures['serving_default']\n",
        "        print(\"Model loaded successfully.\")\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "id": "3dKhT-_8nUIK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_metadata_with_images(metadata):\n",
        "    \"\"\"\n",
        "    Filters metadata to include only entries with non-empty 'images' lists.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): The original metadata dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: A filtered metadata dictionary with entries that have images.\n",
        "    \"\"\"\n",
        "    return {key: value for key, value in metadata.items() if value.get(\"images\")}"
      ],
      "metadata": {
        "id": "LU5h3hAcaiIE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata Verification\n",
        "def verify_metadata(metadata):\n",
        "    \"\"\"\n",
        "    Verifies metadata integrity by checking for missing or inconsistent entries.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): The metadata dictionary to verify.\n",
        "    \"\"\"\n",
        "    for key, value in metadata.items():\n",
        "        if not isinstance(value, dict) or \"Plemeno\" not in value or \"Barva\" not in value or \"VÄ›k\" not in value or \"Velikost\" not in value or \"images\" not in value:\n",
        "            print(f\"Warning: Incomplete metadata for key {key}: {value}\")\n",
        "\n",
        "# Function to fix orientation using EXIF\n",
        "def fix_orientation(image):\n",
        "    \"\"\"\n",
        "    Adjust the image orientation based on its EXIF metadata to account for camera rotation.\n",
        "    The function looks for the 'Orientation' tag in the EXIF data and rotates the image accordingly.\n",
        "\n",
        "    Arguments:\n",
        "    image -- The image to fix the orientation for (PIL Image object).\n",
        "\n",
        "    Returns:\n",
        "    PIL Image with corrected orientation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = image._getexif()\n",
        "        if exif is not None:\n",
        "            orientation = exif.get(orientation)\n",
        "            if orientation == 3:\n",
        "                image = image.rotate(180, expand=True)\n",
        "            elif orientation == 6:\n",
        "                image = image.rotate(270, expand=True)\n",
        "            elif orientation == 8:\n",
        "                image = image.rotate(90, expand=True)\n",
        "    except (AttributeError, KeyError, IndexError):\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "# Function to crop and resize the image based on a bounding box\n",
        "\n",
        "    \"\"\"\n",
        "    Crops the image using a given bounding box and then resizes it to the target size.\n",
        "\n",
        "    Arguments:\n",
        "    image -- The image to crop and resize (TensorFlow Tensor).\n",
        "    bounding_box -- A tuple (x1, y1, x2, y2) specifying the coordinates of the bounding box.\n",
        "    target_size -- The target size (height, width) to resize the image to.\n",
        "\n",
        "    Returns:\n",
        "    The cropped and resized image (TensorFlow Tensor).\n",
        "    \"\"\"\n",
        "\n",
        "def crop_and_resize(image, bounding_box, target_size):\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    x1, y1, x2, y2 = bounding_box\n",
        "    image = tf.strided_slice(image, [int(y1), int(x1), 0], [int(y2), int(x2), 3])\n",
        "    image = tf.image.resize(image, target_size)\n",
        "    return image\n",
        "\n",
        "# Function to detect pets in the image (Placeholder function, adjust as needed)\n",
        "def detect_pet(image):\n",
        "    load_detector_model()\n",
        "    input_tensor = tf.image.resize(image, [640, 640]) / 255.0\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "    input_tensor_uint8 = tf.cast(input_tensor * 255.0, tf.uint8)\n",
        "\n",
        "    result = detector(tf.convert_to_tensor(input_tensor_uint8))\n",
        "    result = {key: value.numpy() for key, value in result.items()}\n",
        "\n",
        "    if 'detection_classes' in result and 'detection_scores' in result:\n",
        "        detected_classes = result['detection_classes']\n",
        "        detected_boxes = result['detection_boxes']\n",
        "        detected_scores = result['detection_scores']\n",
        "        pet_classes = [b\"Cat\", b\"Dog\", b\"Animal\"]\n",
        "\n",
        "        for idx in range(len(detected_classes[0])):\n",
        "            detected_class = detected_classes[0][idx]\n",
        "            detected_score = detected_scores[0][idx]\n",
        "            detected_box = detected_boxes[0][idx]\n",
        "\n",
        "            if detected_class in pet_classes and detected_score > 0.5:\n",
        "                return detected_box\n",
        "    return None\n",
        "\n",
        "# Function to visualize the image\n",
        "def visualize_image(image, title=\"Processed Image\", visualize=False):\n",
        "    \"\"\"\n",
        "    Visualizes the processed image using Matplotlib.\n",
        "\n",
        "    Arguments:\n",
        "    image -- The image to visualize, can be a TensorFlow tensor or a NumPy array.\n",
        "    title -- The title to display on top of the image.\n",
        "    visualize -- A flag to control whether to visualize the image. Default is True.\n",
        "    \"\"\"\n",
        "    if visualize:\n",
        "        # Convert TensorFlow tensor to NumPy array if necessary\n",
        "        if isinstance(image, tf.Tensor):\n",
        "            image = image.numpy()\n",
        "\n",
        "        # If it's an RGB image, clip pixel values to the range [0, 1]\n",
        "        if image.ndim == 3 and image.shape[-1] == 3:\n",
        "            image = np.clip(image, 0, 1)\n",
        "        elif image.ndim == 2:  # If grayscale, clip to [0, 255]\n",
        "            image = np.clip(image, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Show the image using Matplotlib\n",
        "        plt.imshow(image)\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "# Download and Preprocess Image\n",
        "def download_and_preprocess_image(url, target_size=(224, 224), visualize=False):\n",
        "    response = requests.get(url)\n",
        "    image_bytes = response.content\n",
        "    pil_image = Image.open(io.BytesIO(image_bytes))\n",
        "    pil_image = fix_orientation(pil_image)\n",
        "\n",
        "    image = tf.convert_to_tensor(np.array(pil_image), dtype=tf.float32) / 255.0\n",
        "    bounding_box = detect_pet(image)\n",
        "\n",
        "    if bounding_box is not None:\n",
        "        image = crop_and_resize(image, bounding_box, target_size)\n",
        "    else:\n",
        "        # If no pet detected, resize with padding\n",
        "        image = tf.image.resize_with_crop_or_pad(image, target_size[0], target_size[1])\n",
        "\n",
        "    # Visualize the image if needed\n",
        "    visualize_image(image, title=\"Processed Image\", visualize=visualize)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "PKEM6JzRnODf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function processes image data from a metadata dictionary and prepares it for training in a machine learning model using TensorFlow."
      ],
      "metadata": {
        "id": "XJ1TWxIa2dh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def preprocess_pipeline(metadata, target_size=(224, 224), visualize=False):\n",
        " #   images = []\n",
        "  #  labels = []\n",
        "   # for key, entry in metadata.items():\n",
        "    #    image_urls = entry[\"images\"]\n",
        "\n",
        "        # Create a label (list of characteristics)\n",
        "     #   label = [\n",
        "      #      entry.get(\"Plemeno\", \"Unknown\"),\n",
        "       #     entry.get(\"VÄ›k\", \"Unknown\"),\n",
        "        #    entry.get(\"Barva\", \"Unknown\"),\n",
        "         #   entry.get(\"Velikost\", \"Unknown\")\n",
        "\n",
        "        # Process all the images in the 'images' list\n",
        "      #  for image_url in image_urls:\n",
        "       #     image = download_and_preprocess_image(image_url, target_size, visualize)\n",
        "        #    images.append(image)\n",
        "         #   labels.append(label)  # Append the same label for each image\n",
        "\n",
        "  #  return tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "def preprocess_dataset(metadata, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocesses the dataset to create pairs of images for the same pet and different pets.\n",
        "    The output dataset contains the attributes and image pairs.\n",
        "    \"\"\"\n",
        "    data_pairs = []\n",
        "\n",
        "    # First, create image pairs from the same pet (label = 1)\n",
        "    for key, entry in metadata.items():\n",
        "        # Get the pet attributes\n",
        "        plemeno = entry.get(\"Plemeno\", \"Unknown\")\n",
        "        vek = entry.get(\"VÄ›k\", \"Unknown\")\n",
        "        barva = entry.get(\"Barva\", \"Unknown\")\n",
        "        velikost = entry.get(\"Velikost\", \"Unknown\")\n",
        "\n",
        "        # Get all the images for this pet\n",
        "        images = entry.get(\"images\", [])\n",
        "\n",
        "        #if len(images) < 2:\n",
        "         #   continue  # Skip pets with fewer than 2 images\n",
        "\n",
        "        # Pair each image with every other image for the same pet\n",
        "        for i in range(len(images)):\n",
        "            for j in range(i + 1, len(images)):\n",
        "                # Download and preprocess both images\n",
        "                image1 = download_and_preprocess_image(images[i], target_size)\n",
        "                image2 = download_and_preprocess_image(images[j], target_size)\n",
        "\n",
        "                # Add to data pairs with label = 1 (same pet)\n",
        "                data_pairs.append(((plemeno, vek, barva, velikost, image1, image2), 1))\n",
        "\n",
        "    # Now create image pairs from different pets (label = 0)\n",
        "    all_keys = list(metadata.keys())\n",
        "    for key1, key2 in itertools.combinations(all_keys, 2):\n",
        "        entry1 = metadata[key1]\n",
        "        entry2 = metadata[key2]\n",
        "\n",
        "        # Get the attributes and images for both pets\n",
        "        plemeno1 = entry1.get(\"Plemeno\", \"Unknown\")\n",
        "        vek1 = entry1.get(\"VÄ›k\", \"Unknown\")\n",
        "        barva1 = entry1.get(\"Barva\", \"Unknown\")\n",
        "        velikost1 = entry1.get(\"Velikost\", \"Unknown\")\n",
        "        images1 = entry1.get(\"images\", [])\n",
        "\n",
        "        plemeno2 = entry2.get(\"Plemeno\", \"Unknown\")\n",
        "        vek2 = entry2.get(\"VÄ›k\", \"Unknown\")\n",
        "        barva2 = entry2.get(\"Barva\", \"Unknown\")\n",
        "        velikost2 = entry2.get(\"Velikost\", \"Unknown\")\n",
        "        images2 = entry2.get(\"images\", [])\n",
        "\n",
        "        if not images1 or not images2:\n",
        "            continue  # Skip if either pet doesn't have images\n",
        "\n",
        "        # Pair the first image of pet 1 with the first image of pet 2 (label = 0)\n",
        "        image1 = download_and_preprocess_image(images1[0], target_size)\n",
        "        image2 = download_and_preprocess_image(images2[0], target_size)\n",
        "\n",
        "        # Add to data pairs with label = 0 (different pets)\n",
        "        data_pairs.append(((plemeno1, vek1, barva1, velikost1, image1, image2), 0))\n",
        "\n",
        "    # Convert to a TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data_pairs)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Zsz7r57y1xUh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will display a specified number of sample images from the dataset, with the corresponding labels shown as the image title."
      ],
      "metadata": {
        "id": "AW3mtPkN2uE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Sample Visualization\n",
        "def visualize_dataset_sample(dataset, num_samples=5):\n",
        "    for image, label in dataset.take(num_samples):\n",
        "        plt.imshow(image.numpy())\n",
        "        plt.title(f\"Label: {label.numpy().decode()}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "IzbG8Y3_1387"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into parts: training, validation and test data.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QRZliIqo9aYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(dataset, val_split=0.1, test_split=0.1):\n",
        "    total_size = len(dataset)\n",
        "    val_size = int(val_split * total_size)\n",
        "    test_size = int(test_split * total_size)\n",
        "\n",
        "    val_dataset = dataset.take(val_size)\n",
        "    test_dataset = dataset.skip(val_size).take(test_size)\n",
        "    train_dataset = dataset.skip(val_size + test_size)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "pnapjKEv9K7M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function prepares the dataset by batching it into groups of a specified size. It can also shuffle the dataset before batching and prefetch it to optimize performance."
      ],
      "metadata": {
        "id": "Citsl0HQ3hMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Batching\n",
        "def batch_dataset(dataset, batch_size=32, shuffle=True):\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "hoevYCrQ2AIw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Fetching metadata...\")\n",
        "    metadata = get_data()\n",
        "    verify_metadata(metadata)\n",
        "\n",
        "    #print(\"Filtering metadata to remove entries without images...\")\n",
        "    filtered_metadata = filter_metadata_with_images(metadata)\n",
        "    print(f\"Filtered metadata contains {len(filtered_metadata)} entries (original: {len(metadata)})\")\n",
        "\n",
        "    # Limit to the specified entries for testing\n",
        "    filtered_metadata = dict(islice(filtered_metadata.items(), 2))\n",
        "    print(f\"Using the first {len(filtered_metadata)} entries for testing.\")\n",
        "\n",
        "    verify_metadata(filtered_metadata)\n",
        "\n",
        "    print(\"Creating dataset...\")\n",
        "    dataset = preprocess_pipeline(metadata)\n",
        "\n",
        "    # Print out some example data from the dataset\n",
        "#for data, label in dataset.take(3):  # Show first 3 samples\n",
        " #   print(f\"Attributes: {data[:4]}\")  # First 4 elements are the pet's attributes\n",
        "  #  print(f\"Image1: {data[4]}\")  # Image 1\n",
        "   # print(f\"Image2: {data[5]}\")  # Image 2\n",
        "    #print(f\"Label: {label}\")  # Label: 1 or 0\n",
        "\n",
        "    #print(\"Visualizing dataset samples...\")\n",
        "    #visualize_dataset_sample(dataset, num_samples=3)"
      ],
      "metadata": {
        "id": "KwL9xoSM19eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: label encoding, image augmentation?, performance optimization - parallel processing ..."
      ],
      "metadata": {
        "id": "gESHyuRcAp1x"
      }
    }
  ]
}